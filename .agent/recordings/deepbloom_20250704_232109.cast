{"version":2,"width":106,"height":32,"timestamp":1751667670,"command":"bash /home/thomas/Projects/claude.sh/claude.sh-refactor/agent.sh --prompt-file=/home/thomas/Projects/claude.sh/claude.sh-refactor/DEEPBLOOM_flash-consortium-i2.md $'<CODE>\\npwd\\ntree -I .venv -I build -I dist -I __pycache__ -I test_env -I venv -I node_modules -I .git -I .mypy_cache -I .pytest_cache\\n</CODE>\\n/home/thomas/Projects/llm/plugins/Utilities/llm-jina\\n.\\n├── HELP_REQUEST.md\\n├── jina-metaprompt.md\\n├── llm_jina\\n│   └── __init__.py\\n├── poetry.lock\\n├── pyproject.toml\\n├── pytest.ini\\n├── README.md\\n├── src\\n│   ├── __init__.py\\n│   └── llm_jina\\n│       ├── classifier.py\\n│       ├── client.py\\n│       ├── code_agent\\n│       │   ├── codegen_prompt.txt\\n│       │   ├── executor.py\\n│       │   ├── feedback_prompt.txt\\n│       │   ├── generator.py\\n│       │   ├── __init__.py\\n│       │   ├── refiner.py\\n│       │   ├── testgen_prompt.txt\\n│       │   ├── utils.py\\n│       │   └── validator.py\\n│       ├── commands.py\\n│       ├── deepsearch.py\\n│       ├── embeddings.py\\n│       ├── exceptions.py\\n│       ├── __init__.py\\n│       ├── metaprompt.py\\n│       ├── reader.py\\n│       ├── rerank.py\\n│       ├── search.py\\n│       └── segmenter.py\\n└── tests\\n    ├── __init__.py\\n    ├── integration\\n    │   └── __init__.py\\n    └── unit\\n        ├── __init__.py\\n        ├── test_code_agent_workflow.py\\n        └── test_simple_cli.py\\n\\n8 directories, 34 files\\n\\nIt looks like this is not logging prompts to the llm logs db as it should. Can you verify?\\n\\nIf you don\\'t know how to do this or need more help consult simonw\\'s LLM library docs at /home/thomas/Projects/llm/my-llm/llm-thomas/docs/' -m=gemini-pro","env":{"SHELL":"/usr/bin/zsh","TERM":"xterm-256color"},"theme":{"fg":"#3b3b3b","bg":"#f8f8f8","palette":"#000000:#cd3131:#107c10:#949800:#0451a5:#bc05bc:#0598bc:#555555:#666666:#cd3131:#14ce14:#b5ba00:#0451a5:#bc05bc:#0598bc:#a5a5a5"}}
[3.433358, "o", "-- Loading resources from /home/thomas/.sqliterc\r\n"]
[3.499558, "o", "-- Loading resources from /home/thomas/.sqliterc\r\n"]
[3.560787, "o", "Initiating self-awareness with model gemini-pro...\r\n"]
[4.922166, "o", "Self-awareness initiation: Falling back to get conversation ID by UUID.\r\n"]
[6.032822, "o", "Error: Could not initiate self-awareness. Failed to get conversation_id or response_id.\r\n"]
[6.033191, "o", "Warning: Insufficient IDs to copy initial log.\r\n"]
[7.008699, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[9.249802, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[11.482736, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[13.699929, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[15.953871, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[18.199533, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[20.460633, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[22.714098, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[24.968013, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[27.238467, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[29.472839, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[31.718845, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[33.951531, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[36.214003, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[38.474125, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[40.712006, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[42.959475, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[45.199394, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[47.448545, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[49.686829, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[51.958364, "o", "Response:\r\nError: 'Unknown model: gemini-pro'\r\n"]
[53.648547, "o", "^C"]
